{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "b1697f57eb706aae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Advanced LLM Prompt Cache Architecture Overview\n",
    "We'll cover several high-level sections from Hardware to Software and Algorithms with intrigue in-between.\n",
    "\n",
    "## Hardware-Level Caching\n",
    "\n",
    "### Leveraging the Chip Layer Caches\n",
    "- Big Cache, sure... L1, L2, L3\n",
    "- Choosing your hardware purposefully, eg \"EPYC MegaL3 Cache\"* vs \"Xeon MAX\"**\n",
    "\n",
    "- [*] Not its formal marketing name, but close\n",
    "- [**] This is its actual marketing name\n",
    "\n",
    "### DRAM Faster All The Time\n",
    "DDR4 is no more.. we go with DDR5 and soon DDR6, and we'll see HMB, HMB2, and other designs in different ways.\n",
    "\n",
    "#### Concerns for DRAM\n",
    "- NUMA, and it applies to chiplet designs just as much as it applies to multi-socket motherboards.\n",
    "- Interleaved memory: and how it can be used to improve performance, improve high-availability, as well as concerns about degrading performance if the design does not fit the requirements.\n",
    "- Memory channel density: this can increase total DRAM density, though in some architectures there is a DRAM speed penalty for populating more than 1 DIMM per Channel (1DPC).\n",
    "\n",
    "\n",
    "### NVMe are not all equal\n",
    "- U.2, U.3, AIC, or Rulers? Different specs all around, and their interconnects to the PCIe bus make a substantial difference.\n",
    "- SLC on there, is it an SLC cache or is the full NAND array made of SLC\n",
    "\n",
    "### RDMA and Network Shared Memory\n",
    "Is OpenMPI ever enough? Is RDMA what we want? Why not Myrcom\n",
    "\n",
    "#### Interconnect Designs for Memory Nets\n",
    "As a starting point, the Torus has been a highly performing base architecture for Top-500 supercomputers. More on that here:\n",
    "- https://en.wikipedia.org/wiki/Torus_interconnect#Performance\n",
    "\n",
    "Variations on the theme, including SeaStar and Gemini interconnects are described here:\n",
    "- https://github.com/jeffhammond/HPCInfo/blob/master/docs/Cray.md\n",
    "\n",
    "#### Memory Passing Interface - aka MPI\n",
    "What would be do with a shared memory network if not pass data back and forth between compute nodes? Yes, and in a standardized manner, where MPI offers plenty of examples. This has been an evolving field of computer science, which deserves a variety of source code examples and tutorials:\n",
    "- From the great Jeff Hammond: https://github.com/jeffhammond/HPCInfo/tree/master/mpi\n",
    "- Lawrence Livermore Labs gets a mention: https://hpc-tutorials.llnl.gov/mpi/\n",
    "\n",
    "\n",
    "### Multi-Node Distributed Caching\n",
    "This necessarily involves an amalgam of the various cache layers and technologies, and so we'll simply consider this to be the default when dealing with clusters of KVUs.\n",
    "\n",
    "#### Shared Considerations on Timing\n",
    "This applies to shared and non-shared resource clusters, and it is the resource of Time.\n",
    "- Are we using a strict Precision Time Protocol system, Stratum-1 or are we leveraging NTP's global pool for Stratum-2 sync?\n",
    "- Are the NICs the Source of Truth for Network Time, or do we have a separate SMA connection on the wire for PTP data distribution?\n",
    "\n",
    "#### Considerations on Shared-Nothing Clusters\n",
    "- Which layer controls cache coherency across the cluster if not the shared-resource controller service?\n",
    "- Is there cache-coherency or is this a broadcast-type information domain where the First Responder wins?\n",
    "- If we share nothing across the nodes, how do we prevent split-brain issues where more than one individual node tries to answer first and wastes resources when multiple nodes are trying for the same connection?\n",
    "\n",
    "\n",
    "#### Considerations on Shared-Resource Clusters\n",
    "- Scaling algos, pre-determined calculations abound.\n",
    "- Must control for N-th order latency and bandwidth for resource communications over the fabric.\n",
    "- Do we have a single shared L2 domain fabric with ALCs, or a segmented L3, or layered L3 with VxLAN or Mesh-VPN/type networks-within-networks?\n",
    "- How are the switching layers impacted on node scaling baselines?\n",
    "- Are we using a 1:1 mapping for ports between node-to-node or node-to-spine or node-to-leaf?\n",
    "- And so forth...\n",
    "\n",
    "#### Hybrid Cluster Designs\n",
    "This is a combination, in simpler terms it's effectively a \"Shared Some-Things\" instead of 100% None vs 100% Everything (Disk, Memory, Network, CPU cycles via Swarm / OpenMP).\n",
    "\n",
    "#### Exceptions to Multi-Node\n",
    "The exceptions include hypothetical designs like the following, and others of one's imagination. Real-world examples abound, but are out of scope for this document at present.\n",
    "\n",
    "- Micro-Cluster: A single CS-N with 2-4U compute nodes, vertically scaled for high-density resources per node, leveraging 10s-100s of VMs per single-node.\n",
    "    - Each single physical node could be deployed as a single dedicated tenant, similar in concept to using single-physical L2 network domains for dis-aggregation and strong physical isolation of systems when logical partitioning is not relevant by CSO requirements or DoD spec or similar architectural design requirement.\n",
    "    - In this design the VMs could participate in aggregation-level distributed caching internally to the physical node, but would not leverage hardware offloads directly on NICs or DPUs unless distributed via SR-IOV or NPAR style controls within the single-node's OS and kernel + CGroups security layers.\n",
    "\n",
    "\n",
    "## Application Level Caching\n",
    "The following list can be expanded into sub-sections if desired.\n",
    "\n",
    "- Semantic Cache Algorithms\n",
    "- Library Layer Cache Optimizers\n",
    "- Template and Prefix Caching\n",
    "- Multi-Turn Conversions\n",
    "- RAG and Top-K Concerns\n",
    "- Vector Embeds, aka The Matryoshka Method\n",
    "- SDK Optimizers Per-Platform\n",
    "\n",
    "\n",
    "## The Many Methods of Popularized Cache Algorithms\n",
    "\n",
    "### Most Recently Used (MRU)\n",
    "MRU evicts the most recently used item, which can be useful in page-scanning engines or cyclical-control loop caches. This operates under the assumption that the MRU item was scanned and accessed, but then will not be referenced again until the next full-loop or full-cycle/page. It is useful in very specific circumstances, or as a layered algo with trigger calls to enable/disable its functionality as-needed.\n",
    "\n",
    ". MRU is only beneficial in specific patterns (like scanning cyclical patterns). It’s generally not used as a primary policy in caching systems for LLMs, except possibly in some layered buffer situations.\n",
    "\n",
    "### Least Recently Used (LRU)\n",
    "Possibly the most commonly seen cache algo in the wild, LRU evicts items accessed the longest time ago, operating via the assumption that if it hasn’t been used in a while then it’s less likely to be needed soon. Downside: LRU only tracks recency, not frequency of use, and has no weighting controls.\n",
    "\n",
    "### LRU variants (2Q, LRU/K, etc)\n",
    "- 2Q is a strategy that introduces a probationary queue and a protected queue\n",
    "- LRU/K and LRU/2 track the k-th most recent access rather than the last access when making eviction decisions\n",
    "\n",
    "### Least Frequently Used (LFU)\n",
    "Evicts the item with the lowest access count to better capture long-term hot items vs cold items, another entry in the list of comparatively simple cache algos.\n",
    "\n",
    "### Random\n",
    "As it stands, it's A method, but not an often-best method for cache controls.\n",
    "\n",
    "### First In First Out (FIFO)\n",
    "A circular buffer type cache policy, similar to Round-Robin method in Load-Balancing controls. Very simple, and sometimes KISS is all that's needed.\n",
    "\n",
    "### Clock Second Chance (CSCh)\n",
    "An approximation of LRU used in OS kernel page replacement, which arranges pages in a circular buffer like a clock and gives a \"second chance\" to pages that have been accessed recently by marking them before eviction. Effectively this is a Round-Robin method with a simple weighting system.\n",
    "\n",
    "### Adaptive Replacement Cache (ARC)\n",
    "ARC is a highly regarded algorithm that adapts between LRU and LFU dynamically, algorithmically defined via tunables, used in the ZFS filesystem's DRAM and L2 data segments, as well as various applications which require real-time analysis and automated tuning of the caching system. This is the most advanced of the cache controls described here.\n",
    "\n",
    "### Segmented LRU (S/LRU)\n",
    "Takes the LRU method and splits cache entries into segments, referred to as \"protected vs probationary\".\n",
    "\n",
    "### Window TinyLFU (Wt/LFU)\n",
    "An advancement upon the standard LFU policy which uses a small LRU \"windowing controller\" and adapts the concept of \"TinyLFU\" for its cache admission policy design. These actions can be modeled by ARC and improved upon dynamically, where-as the non-ARC methods of Wt/LFU may become stale over time or induce inefficiency which is difficult to change during production use - unless real-time controls are implemented.\n",
    "\n",
    "## Innovative Cache Designs\n",
    "\n",
    "- Learning-Based Cache Evictions\n",
    "- Content-Based Caching\n",
    "- Hierarchical Cooperative Caching\n",
    "- Disaggregated Network Caching with Memory Pooling\n",
    "- Multi-Modal Caching, Internalized\n",
    "- Write-Cache Persistence Cycles\n",
    "- Dynamic Cache Partitioning\n",
    "- Cache-within-a-Cache, using Caches to Cache other Cache Info\n",
    "\n",
    "## Cache-Object Invalidation Strategies\n",
    "- Common strategies include time-to-live (TTL)\n",
    "- Object Not Found Error (ONFE)\n",
    "\n",
    "### Cache Propagation Strategies\n",
    "- First-Order Connection Fan-Out\n",
    "- Multicast Subnet ACLs\n",
    "- Unicast Subnet ACLs\n",
    "\n",
    "### Invalidation Layered Invalidation Methods\n",
    "- Object Origin Dead on Arrival (OO-DoA)\n",
    "- Object Origin Dead on Health-Check (OO-DoHC)\n",
    "\n",
    "\n",
    "\n",
    "## Concerns in Caching Architectures\n",
    "This topic is extensive, and for the current scope I'll cover the high-level sections. If or when those need further clarifications, then the topics may be expanded upon.\n",
    "\n",
    "### Stale Data and Invalidation Issues\n",
    "How do we handle this... it's like asking \"Which bear is the best bear?\".. not a simple answer.\n",
    "\n",
    "### Cache Consistency Across Multi-Node Clusters\n",
    "This involves cache invalidation, stale data, awareness and coherency, split-brain concepts, and everything in-between but not limited to whether we should use fan-out, broadcast, target-steering, traffic-directors, or some manner of snake oil to solve the many concerns.\n",
    "\n",
    "### The Stampeding Thunderous Herd was Heard on All Nodes\n",
    "Jokes aside, this ages old concern about connection floods is felt not only on cache node systems involved with mass-invalidation or mass-resync or mass-N actions.\n",
    "\n",
    "It's a concern on datacenter power policy when an entire rack power cycles without a turn-up plan -- should all nodes immediately power on after power-loss or should there be a randomized counter to ensure that the UPS or PDUs or upstream delivery systems are not slammed all at once and blow caps or smash breakers.\n",
    "\n",
    "We see this issue in many areas of infrastructure, civil engineering, aerospace engineering, computer science, and even our own neuroendocrine system which we really don't want to flood the brain with catecholamines during a stressful event - because then you get shock, cardiac arrest, vascular issues leading to aneurysm.\n",
    "\n",
    "### Cache Pollution or Cache-Affinity Overuse\n",
    "If an algo is tuned incorrectly or inefficiently, we can see certain \"hot nodes\" being worn our on TBW disk load, or NICs constantly at peak instead of load being distributed across adjacent nodes, or we see de-serialization issues, chunking inefficiency, and so forth.\n",
    "\n",
    "### Over-Serialization and Transport Cost Overload\n",
    "Moving data back and forth between nodes, across spine and leafs, through DPU caches, through off-loader chips, etc.. these actions all have costs: power costs, latency inductions, bandwidth usage, compute cycles, etc. If transport is being inefficiently used due to poorly tuned algos, then we see cost increases occuring unnecessarily, and wear rates being exceeded earlier than they would if the cache efficiency were more effective. This is an overall systems engineering optimization and performance engineering analysis side of cache controls.\n",
    "\n",
    "### Memory Leaks and Resource Locks\n",
    "As their tites say, these are issues with programming and resource alignments. These can occur in myriad situations, which can cover entire chapters. Such as they are, they can cause extensive issues and preventative measures must be employed to identify their occurrence before production implementation, as well as checks for production to find and resolve or mitigate before large-scale cache propagation occurs.\n",
    "\n",
    "### Over-Caching of Data and Data-Couplers\n",
    "Sometimes there's a greater cost and performance efficiency by not caching data across a cluster, and sometimes coupling indirect data or metadata with the original data is more of less effective than its opposite. These topics can be expanded upon if necessary.\n",
    "\n",
    "\n",
    "## Standardizing the Architecture Design Process, References\n",
    "\n",
    "We can reference the following concepts for correctness and usage. These are a subset of my preferred methods, primarily high-level approaches which are helpful for narrowing down the decision-arrival process while attempting to ensure adherence to a level of consistency in Correctness-Defined.\n",
    "\n",
    "- \"Markdown Architectural Decision Records\", https://adr.github.io/madr/\n",
    "- \"Architecturally significant requirements\", https://en.wikipedia.org/wiki/Architecturally_significant_requirements\n",
    "- \"Attribute Driven Design\", https://en.wikipedia.org/wiki/Attribute-driven_design\n",
    "- \"Definition of Done\", https://ozimmer.ch/practices/2020/05/22/ADDefinitionOfDone.html\n",
    "- \"Definition of Ready\", https://ozimmer.ch/practices/2023/12/01/ADDefinitionOfReady.html\n",
    "- \"ADR Templates\", https://adr.github.io/adr-templates/\n",
    "- \"Decision Capturing Tools\", https://adr.github.io/adr-tooling/"
   ],
   "id": "ae49f5ecf9a84a52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
